{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit emission lines in Sitelle data <a class=\"tocSkip\">\n",
    "\n",
    "This notebook is used to run the ORBS pipeline to create [OII] linemaps from the raw hdf5 cubes. Any further analysis should go in the dedicated notebooks.\n",
    "    \n",
    "* [ORB](https://orb.readthedocs.io) documentation\n",
    "* [ORCS](https://orcs.readthedocs.io/en/latest/index.html) documentation\n",
    "* [ORBS](https://github.com/thomasorb/orbs) github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload modules after they have been modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy.io import fits,ascii\n",
    "from astropy.table import Table, vstack, join\n",
    "\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import Distance,SkyCoord\n",
    "\n",
    "from astropy.visualization import simple_norm\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.nddata import NDData, Cutout2D\n",
    "\n",
    "import astropy.constants as c\n",
    "import astropy.units as u\n",
    "\n",
    "from reproject import reproject_interp\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('Tex.mplstyle')\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout,format='%(levelname)s: %(message)s',level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "single_column = 3.321 # in inch\n",
    "two_column    = 6.974 # in inch\n",
    "\n",
    "basedir  = Path('..')\n",
    "data_raw = Path('/mnt/a/Archive/') \n",
    "\n",
    "output_folder = 'data_v2p3'\n",
    "\n",
    "with fits.open(basedir/'data'/'phangs_sample_table_v1p6.fits') as hdul:\n",
    "    sample_table = Table(hdul[1].data)\n",
    "sample_table['name'] = [x.upper() for x in sample_table['name']]\n",
    "sample_table.add_index('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Read in data\n",
    "\n",
    "the complete data set is only needed to extract the spectra or make a line map\n",
    "\n",
    "it might be necassary to mount the external drive first\n",
    "`sudo mount -t drvfs a: /mnt/a`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from orcs.process import SpectralCube\n",
    "import yaml\n",
    "\n",
    "name = 'NGC2835'\n",
    "\n",
    "filename = data_raw / 'SITELLE' /f'{name}_cube.hdf5'\n",
    "cube = SpectralCube(filename)\n",
    "print(cube.params['object_name'])\n",
    "\n",
    "# the WCS information in the fits cubes is correct\n",
    "filename = data_raw/'SITELLE'/f'{name}_cube.fits'\n",
    "with fits.open(filename) as hdul:\n",
    "    header = hdul[0].header\n",
    "wcs = WCS(header,naxis=2)\n",
    "#cube.set_wcs(wcs)\n",
    "\n",
    "# read in the deepframe file to get the correct 2d header\n",
    "filename = data_raw/'SITELLE'/f'{name}_deepframe.fits'\n",
    "with fits.open(filename) as hdul:\n",
    "    deepframe = NDData(data=hdul[0].data,\n",
    "                    meta=hdul[0].header,\n",
    "                    # for some reason the deepframe does not contain a valid WCS information\n",
    "                    wcs=wcs)    \n",
    "    \n",
    "params = cube.params\n",
    "parameter_file = basedir/'data'/output_folder/'params'/f'{name}_params.yaml'\n",
    "if not parameter_file.is_file() or True:\n",
    "    print('saving cube parameters to file')\n",
    "    keys = ['object_name','date','dimx','dimy','dimz','step','order','nm_laser','axis_corr','zpd_index']\n",
    "    dic = {key:params.get(key) for key in keys}\n",
    "    dic['channel_width'] = float(params.base_axis[1] - params.base_axis[0])\n",
    "    for k,v in dic.items():\n",
    "        if isinstance(v,np.int64):\n",
    "            dic[k] = int(v)\n",
    "    with open(parameter_file,'w+') as f:\n",
    "        yaml.dump(dic,f)\n",
    "else:  \n",
    "    with open(parameter_file) as f:\n",
    "        params = yaml.load(f,Loader=yaml.SafeLoader)\n",
    "    \n",
    "# save deepframe with correct wcs\n",
    "#primary_hdu = fits.PrimaryHDU(data=deepframe.data,header=deepframe.meta)\n",
    "#primary_hdu.writeto(basedir/'data'/f'{name}_deepframe.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DR = 'DR2.1'\n",
    "\n",
    "if DR=='DR1':\n",
    "    catalogue_file = data_raw/'MUSE'/'DR1.0'/'Nebulae catalogue'/'Nebulae_Catalogue.fits' \n",
    "    filter_file = data_raw/'MUSE'/'DR1.0'/'filterImages'/f'{name}_IMAGE_FOV_Johnson_B.fits'\n",
    "    mask_file = data_raw/'MUSE'/'DR1.0'/'Nebulae catalogue'/'spatial_masks'/f'{name}_HIIreg_mask.fits'.format(name) \n",
    "elif DR=='DR2.0':\n",
    "    catalogue_file = data_raw/'MUSE'/'DR2.0'/'Nebulae catalogue'/'Nebulae_Catalogue_DR2_native.fits' \n",
    "    filter_file = data_raw/'MUSE'/'DR2.0'/'filterImages'/f'{name}_IMAGE_FOV_Johnson_B_WCS_Pall_mad.fits'\n",
    "    halpha_file = data_raw/'MUSE'/'DR2.0'/'MUSEDAP'/f'{name}_MAPS.fits'\n",
    "    mask_file = data_raw/'MUSE'/'DR2.0'/'Nebulae catalogue'/'spatial_masks'/f'{name}_HIIreg_mask.fits'.format(name) \n",
    "else:\n",
    "    catalogue_file = data_raw/'Products'/'Nebulae_catalogs'/'Nebulae_catalogue_v2'/'Nebulae_catalogue_v2.fits' \n",
    "    filter_file = data_raw/'MUSE'/'DR2.1'/'filterImages'/f'{name}_IMAGE_FOV_Johnson_B_WCS_Pall_mad.fits'\n",
    "    halpha_file = data_raw/'MUSE'/'DR2.1'/'MUSEDAP'/f'{name}_MAPS.fits'\n",
    "    mask_file = data_raw/'Products'/'Nebulae_catalogs'/'Nebulae_catalogue_v2'/'spatial_masks'/f'{name}_nebulae_mask.fits'.format(name) \n",
    "print(f'using {DR}')\n",
    "    \n",
    "with fits.open(catalogue_file) as hdul:\n",
    "    nebulae_catalogue = Table(hdul[1].data)\n",
    "\n",
    "# muse image for reprojection\n",
    "with fits.open(filter_file) as hdul:    \n",
    "    muse_data = NDData(data=hdul['DATA'].data,\n",
    "                    mask=np.isnan(hdul['DATA'].data),\n",
    "                    meta=hdul['DATA'].header,\n",
    "                    wcs=WCS(hdul['DATA'].header))    \n",
    "    muse_data.data[muse_data.data==0] = np.nan\n",
    "\n",
    "with fits.open(halpha_file) as hdul:    \n",
    "    Halpha = NDData(data=hdul['HA6562_FLUX'].data,\n",
    "                    mask=np.isnan(hdul['HA6562_FLUX'].data),\n",
    "                    meta=hdul['HA6562_FLUX'].header,\n",
    "                    wcs=WCS(hdul['HA6562_FLUX'].header))    \n",
    "    Halpha.data[muse_data.data==0] = np.nan\n",
    "    \n",
    "with fits.open(mask_file) as hdul:\n",
    "    nebulae_mask = NDData(hdul[0].data.astype(float),mask=Halpha.mask,meta=hdul[0].header,wcs=WCS(hdul[0].header))\n",
    "    nebulae_mask.data[nebulae_mask.data==-1] = np.nan\n",
    "\n",
    "nebulae_catalogue = nebulae_catalogue[nebulae_catalogue['gal_name']==name]\n",
    "nebulae_catalogue.add_index('region_ID')\n",
    "nebulae_catalogue['SkyCoord'] = SkyCoord(nebulae_catalogue['cen_ra']*u.degree,nebulae_catalogue['cen_dec']*u.degree)\n",
    "print('{} nebulae in {}'.format(len(nebulae_catalogue),name))\n",
    "print('{} regions in masks'.format(len(np.unique(nebulae_mask.data[~np.isnan(nebulae_mask.data)]))))\n",
    "\n",
    "from region import Regions\n",
    "        \n",
    "muse_regions = Regions(mask=nebulae_mask.data,projection=nebulae_mask.meta,bkg=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Extract spectra from regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# determine the limits of the muse data in the sitelle image\n",
    "a, footprint = reproject_interp(muse_data,output_projection=wcs,shape_out=deepframe.data.shape)\n",
    "\n",
    "xvalues = np.where(np.any(footprint,axis=0))\n",
    "xmin,xmax = np.min(xvalues),np.max(xvalues)\n",
    "yvalues = np.where(np.any(footprint,axis=1))\n",
    "ymin,ymax = np.min(yvalues),np.max(yvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sitelle_regions = muse_regions.reproject(wcs,shape=deepframe.data.shape)\n",
    "sitelle_regions.plot(image=deepframe.data,regions=False,\n",
    "                     filename=basedir/'reports'/name/f'{name}_sitelle_regions.png',\n",
    "                     xlim=[0.95*xmin,1.05*xmax],ylim=[0.95*ymin,1.05*ymax],xlabel='R.A.',ylabel='Dec.', \n",
    "                     percent=99.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "region_id = []\n",
    "axis      = []\n",
    "spectrum  = []\n",
    "\n",
    "for reg,label in zip(sitelle_regions.coords,sitelle_regions.labels):\n",
    "\n",
    "    # ORCS expects y,x coordinates\n",
    "    a,s = cube.extract_integrated_spectrum(reg[::-1])\n",
    "\n",
    "    region_id.append(label)\n",
    "    axis.append(np.float64(a))\n",
    "    spectrum.append(np.real(s))\n",
    "        \n",
    "\n",
    "spectra = Table(data=[region_id,axis,spectrum],\n",
    "                names=['region_ID','axis','spectrum'])\n",
    "\n",
    "spectra['axis'] /= u.cm\n",
    "spectra['spectrum'] *= u.erg/u.cm**2/u.s/u.AA\n",
    "\n",
    "hdu = fits.BinTableHDU(spectra,name='spectra')\n",
    "hdu.writeto(basedir/output_folder/'spectra'/f'{name}_spectra_SN1.fits',overwrite=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit emission line in spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we already extracted all spectra and saved them in a file. Here we load this file and fit the [OII] doublet to the spectra\n",
    "\n",
    "### Define parameters and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyneb as pn\n",
    "\n",
    "def extinction(EBV,EBV_err,wavelength,plot=False):\n",
    "    '''Calculate the extinction for a given EBV and wavelength with errors\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    EBV : array\n",
    "\n",
    "    EBV_err : array\n",
    "\n",
    "    wavelength : float\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    EBV = np.atleast_1d(EBV)\n",
    "    EBV_err = np.atleast_1d(EBV_err)\n",
    "    sample_size = 100000\n",
    "    \n",
    "    ext = pn.RedCorr(R_V=3.1,E_BV=EBV,law='CCM89 oD94').getCorr(wavelength)\n",
    "    \n",
    "    EBV_rand = np.random.normal(loc=EBV,scale=EBV_err,size=(sample_size,len(EBV)))\n",
    "    ext_arr  = pn.RedCorr(R_V=3.1,E_BV=EBV_rand,law='CCM89 oD94').getCorr(wavelength)\n",
    "    \n",
    "    ext_err  = np.std(ext_arr,axis=0)\n",
    "    ext_mean = np.mean(ext_arr,axis=0)\n",
    "    \n",
    "    if plot:\n",
    "        fig,(ax1,ax2) =plt.subplots(nrows=1,ncols=2,figsize=(6,6/2))\n",
    "        ax1.hist(EBV_rand[:,0],bins=100)\n",
    "        ax1.axvline(EBV[0],color='black')\n",
    "        ax1.set(xlabel='E(B-V)')\n",
    "        ax2.hist(ext_arr[:,0],bins=100)\n",
    "        ax2.axvline(ext[0],color='black')\n",
    "        ax2.set(xlabel='extinction')\n",
    "        plt.show()\n",
    " \n",
    "    return ext,ext_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all the data necessary to make a fit is located in the sitelle folder and read in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orb.fit import fit_lines_in_spectrum\n",
    "from orb.core import Lines\n",
    "from orb.utils.spectrum import corr2theta, amp_ratio_from_flux_ratio\n",
    "import gvar\n",
    "\n",
    "name ='NGC2835'\n",
    "\n",
    "print(name)\n",
    "# table with the extracted spectra\n",
    "with fits.open(basedir/'data'/output_folder/'spectra'/f'{name}_spectra_SN1.fits') as hdul:\n",
    "    spectra = Table(hdul[1].data)\n",
    "spectra.add_index('region_ID')\n",
    "\n",
    "# parameters from the cube, needed for the fit\n",
    "parameter_file = basedir/'data'/output_folder/'params'/f'{name}_params.yaml'\n",
    "with open(parameter_file) as f:\n",
    "    params = yaml.load(f,Loader=yaml.SafeLoader)\n",
    "    \n",
    "# the nebulae catalogue (needed for EBV of individual regions)\n",
    "with fits.open(basedir/'data'/output_folder/'Nebulae_Catalogue_v2p1.fits') as hdul:\n",
    "    nebulae_catalogue = Table(hdul[1].data)\n",
    "nebulae_catalogue = nebulae_catalogue[nebulae_catalogue['gal_name']==name]\n",
    "nebulae_catalogue.add_index('region_ID')\n",
    "nebulae_catalogue['SkyCoord'] = SkyCoord(nebulae_catalogue['cen_ra']*u.degree,nebulae_catalogue['cen_dec']*u.degree)\n",
    "\n",
    "distances = {\n",
    "             'IC5332':29.736,'NGC0628':29.9,'NGC1087':30.352,'NGC1300':32.065,'NGC1365':31.242,\n",
    "             'NGC1385':29.659,'NGC1433':31.369,'NGC1512':31.506,'NGC1566':30.884,'NGC1672':30.788,\n",
    "             'NGC2835':30.563,'NGC3351':30.338,'NGC3627':30.133,'NGC4254':30.102,'NGC4303':30.688,\n",
    "             'NGC4321':31.121,'NGC4535':30.99,'NGC5068':28.475,'NGC7496':31.347,\n",
    "            }\n",
    "\n",
    "# EBV of the galaxies\n",
    "EBV = {'IC5332': 0.015,'NGC0628': 0.062,'NGC1087': 0.03,'NGC1300': 0.026,'NGC1365': 0.018,\n",
    "       'NGC1385': 0.018,'NGC1433': 0.008,'NGC1512': 0.009,'NGC1566': 0.008,'NGC1672': 0.021,\n",
    "       'NGC2835': 0.089,'NGC3351': 0.024,'NGC3627': 0.037,'NGC4254': 0.035,'NGC4303': 0.02,\n",
    "       'NGC4321': 0.023,'NGC4535': 0.017,'NGC5068': 0.091,'NGC7496': 0.008}\n",
    "\n",
    "H0 = 70 * u.km / u.s / u.Mpc\n",
    "velocity = H0*Distance(distmod=distances[name])\n",
    "z = (velocity / c.c).decompose().value\n",
    "\n",
    "print(f'velocity={velocity:.1f},z={z:.3f}')\n",
    "\n",
    "OII3726 = Lines().get_line_cm1('[OII]3726')\n",
    "OII3729 = Lines().get_line_cm1('[OII]3729')\n",
    "\n",
    "# channel_width in km/s (velocity must be more precise than this)\n",
    "#channel_width = cube.params.base_axis[1] - cube.params.base_axis[0]\n",
    "#print(f'channel width: {(c.c * channel_width / OII3726).to(u.km/u.s):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_spectrum(spectrum,params,velocity_guess,SNR_guess,sigma_guess=10,flux_ratio=1.4,mode='bayes'):\n",
    "    '''fit the OII doublet in a SITELLE data cube\n",
    "    \n",
    "    https://orcs.readthedocs.io/en/latest/script_example_model%2Bfit_2_lines_bayes.html\n",
    "    '''\n",
    "\n",
    "    # the two lines \n",
    "    OII3726 = Lines().get_line_cm1('[OII]3726')\n",
    "    OII3729 = Lines().get_line_cm1('[OII]3729')\n",
    "    \n",
    "    # get parameters from the cube/header\n",
    "    step       = params.get(\"step\")\n",
    "    order      = params.get(\"order\")\n",
    "    nm_laser   = params.get(\"nm_laser\")\n",
    "    theta      = corr2theta(params.get(\"axis_corr\"))\n",
    "    zpd_index  = params.get(\"zpd_index\")\n",
    "    \n",
    "    amp_ratio = amp_ratio_from_flux_ratio(OII3726,OII3729,flux_ratio)\n",
    "    \n",
    "    # constrain the velocity based on the distance/redshift\n",
    "    velocity_gvar = gvar.gvar(velocity_guess,20)\n",
    "    broadening_gvar = gvar.gvar(1, 20)\n",
    "    \n",
    "    if mode=='classic':\n",
    "        fit = fit_lines_in_spectrum(spectrum, ['[OII]3726', '[OII]3729'], \n",
    "                                    step,order,nm_laser,theta,zpd_index,\n",
    "                                    wavenumber=True, apodization=1, fmodel='sincgauss',\n",
    "                                    pos_def=['1', '1'],\n",
    "                                    pos_cov=[velocity_guess],\n",
    "                                    amp_def='free',\n",
    "                                    amp_guess=[1, amp_ratio],\n",
    "                                    sigma_def=['1','1'],\n",
    "                                    sigma_cov=10\n",
    "                                    )\n",
    "    if mode=='bayes':\n",
    "        fit = fit_lines_in_spectrum(spectrum, [OII3726, OII3729], \n",
    "                                    step,order,nm_laser,theta,zpd_index,\n",
    "                                    wavenumber=True, apodization=1, fmodel='sinc',\n",
    "                                    pos_def=['1', '1'],\n",
    "                                    pos_cov=[velocity_gvar],\n",
    "                                    amp_def=['1','1'],\n",
    "                                    amp_guess=[1, amp_ratio],\n",
    "                                    #sigma_def=['1','1'],\n",
    "                                    #sigma_guess=[broadening_gvar,broadening_gvar],\n",
    "                                    #sigma_cov=10,\n",
    "                                    snr_guess=SNR_guess\n",
    "                                    )\n",
    "    \n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyneb as pn\n",
    "\n",
    "# we use pyneb to estimate the [OII] ratio based on the [SII] ratio\n",
    "O2 = pn.Atom('O', 2)\n",
    "S2 = pn.Atom('S', 2)\n",
    "temp = 1e4\n",
    "\n",
    "# 13, 303, 53,637,525\n",
    "region_ID = 5 #result[np.argmax(result['OII3727_FLUX'])]['region_ID']\n",
    "axis,spectrum = spectra.loc[region_ID][['axis','spectrum']]\n",
    "SNR_old = 3 #result.loc[region_ID]['OII3727_FLUX']/result.loc[region_ID]['OII3727_FLUX_ERR']\n",
    "\n",
    "# we use the velocity from the [NII] line as a prior\n",
    "velocity = sample_table.loc[name]['orient_vlsr']+nebulae_catalogue.loc[region_ID]['NII6583_VEL']+90\n",
    "\n",
    "# we constrain the flux ratio based on the density from the [SII] ratio\n",
    "ratio_S2 = nebulae_catalogue.loc[region_ID]['SII6730_FLUX_CORR'] / nebulae_catalogue.loc[region_ID]['SII6716_FLUX_CORR']\n",
    "density = S2.getTemDen(int_ratio=ratio_S2, tem=temp, wave1=6731, wave2=6717)\n",
    "ratio_O2 = O2.getEmissivity(tem=temp, den=density, wave=3729) /O2.getEmissivity(tem=temp, den=density, wave=3727) \n",
    "\n",
    "\n",
    "fit = fit_spectrum(spectrum,params,velocity,SNR_guess=SNR_old,flux_ratio=ratio_O2,mode='bayes')\n",
    "\n",
    "print(f\"SNR old: {SNR_old:.3f}\")\n",
    "print(f\"SNR new: {fit['flux'][0]/fit['flux_err'][0]:.3f}\")\n",
    "print(f\"[OII]I3729/[OII]3726: {fit['flux'][1]/fit['flux'][0]:.3f}\")\n",
    "\n",
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,4))\n",
    "residual = fit.get_residual().data\n",
    "position = fit['lines_params'][1][2]\n",
    "\n",
    "ax.plot(axis, spectrum, label='spectrum',color='black')\n",
    "ax.plot(axis, residual, label='residual',ls=':',color='grey')\n",
    "\n",
    "OII3726_fit, OII3729_fit = fit['fitted_models']['Cm1LinesModel']\n",
    "\n",
    "ax.plot(axis, fit['fitted_vector'], label='fit', ls='--', c='grey')\n",
    "ax.plot(axis,OII3726_fit,label='OII3726',color='tab:blue')\n",
    "ax.plot(axis,OII3729_fit,label='OII3729',color='tab:red')\n",
    "\n",
    "ax.axvline(OII3726,color='black',label='rest wavenumber')\n",
    "ax.axvline(OII3726/(1+z),color='gray',label='redshifted wavenumber')\n",
    "\n",
    "ax.set(xlim=[position-300,position+300],ylim=[-0.5e-16,None],xlabel=r'wavenumber / cm$^{-1}$',)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'data_v2p4'\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pyneb as pn\n",
    "\n",
    "rc_MW = pn.RedCorr(R_V=3.1,E_BV=EBV[name],law='CCM89 oD94')\n",
    "\n",
    "extinction_mw26  = rc_MW.getCorr(3726)\n",
    "extinction_mw29  = rc_MW.getCorr(3729)\n",
    "\n",
    "# table to save the fluxes\n",
    "fluxes = Table(data=np.full((len(spectra),13),fill_value=np.nan),\n",
    "               names=['region_ID','OII3726_FLUX','OII3729_FLUX','OII3726_FLUX_ERR','OII3729_FLUX_ERR',\n",
    "                      'OII3726_FLUX_CORR','OII3729_FLUX_CORR','OII3726_FLUX_CORR_ERR','OII3729_FLUX_CORR_ERR',\n",
    "                      'OII3726_velocity','OII3729_velocity','OII3726_broadening','OII3729_broadening'])\n",
    "fluxes.add_column(name,index=0,name='gal_name')\n",
    "fluxes['region_ID'] = list(spectra['region_ID'])\n",
    "fluxes.add_index('region_ID')\n",
    "\n",
    "# table to save the line parameters\n",
    "lines_params = Table(data=np.full((len(spectra),11),fill_value=np.nan),\n",
    "               names=['region_ID','height_OII3726','amp_OII3726','pos_OII3726','fwhm_OII3726','sigma_OII3726',\n",
    "                      'height_OII3729','amp_OII3729','pos_OII3729','fwhm_OII3729','sigma_OII3729'])\n",
    "lines_params['region_ID'] = list(spectra['region_ID'])\n",
    "lines_params.add_index('region_ID')\n",
    "\n",
    "# table to save the fitted vector\n",
    "fit_table = spectra.copy()\n",
    "fit_table['OII3726'] = 0*spectra['spectrum']\n",
    "fit_table['OII3729'] = 0*spectra['spectrum']\n",
    "fit_table['fit'] = 0*spectra['spectrum']\n",
    "\n",
    "# we use pyneb to estimate the [OII] ratio based on the [SII] ratio\n",
    "O2 = pn.Atom('O', 2)\n",
    "S2 = pn.Atom('S', 2)\n",
    "temp = 1e4\n",
    "\n",
    "for region_ID in tqdm(fluxes['region_ID']):\n",
    "    \n",
    "    axis,spectrum = spectra.loc[region_ID][['axis','spectrum']]\n",
    "\n",
    "    # we run each fit twice. First with the SNR guess from the classic fit\n",
    "    try:\n",
    "        \n",
    "        # determine priors based on MUSE data\n",
    "        ratio_S2 = nebulae_catalogue.loc[region_ID]['SII6730_FLUX_CORR'] / nebulae_catalogue.loc[region_ID]['SII6716_FLUX_CORR']\n",
    "        density = S2.getTemDen(int_ratio=ratio_S2, tem=temp, wave1=6731, wave2=6717)\n",
    "        ratio_O2 = O2.getEmissivity(tem=temp, den=density, wave=3729) /O2.getEmissivity(tem=temp, den=density, wave=3727) \n",
    "        velocity = sample_table.loc[name]['orient_vlsr']+nebulae_catalogue.loc[region_ID]['NII6583_VEL']+90\n",
    "\n",
    "        SNR = 3 #result.loc[region_ID]['OII3727_FLUX'] / result.loc[region_ID]['OII3727_FLUX_ERR']    \n",
    "        fit = fit_spectrum(spectrum,params,velocity,SNR,flux_ratio=ratio_O2,mode='bayes')\n",
    "        #SNR = fit['snr'][0] #fit['flux'][0]/fit['flux_err'][0]\n",
    "        position = fit['lines_params'][1][2]\n",
    "        residual = fit.get_residual().data\n",
    "        amp = fit['lines_params'][1][1]\n",
    "        std = np.std(residual[(axis>position-100)&(axis<position+100)])\n",
    "        SNR = amp/std\n",
    "        fit = fit_spectrum(spectrum,params,velocity,SNR,flux_ratio=ratio_O2,mode='bayes')\n",
    "\n",
    "        # save the line parameters\n",
    "        lines_params.loc[region_ID][list(lines_params.columns[1:])] = fit['lines_params'].flatten()\n",
    "        \n",
    "        # save the fit result\n",
    "        OII3726_fit, OII3729_fit = fit['fitted_models']['Cm1LinesModel']        \n",
    "        fit_table.loc[region_ID]['OII3726'] = OII3726_fit\n",
    "        fit_table.loc[region_ID]['OII3729'] = OII3729_fit\n",
    "        fit_table.loc[region_ID]['fit']     = fit['fitted_vector']\n",
    "\n",
    "        # the main table\n",
    "        fluxes.loc[region_ID]['OII3726_FLUX','OII3729_FLUX']             = 1e20*fit['flux']\n",
    "        fluxes.loc[region_ID]['OII3726_FLUX_ERR','OII3729_FLUX_ERR']     = 1e20*fit['flux_err']\n",
    "        fluxes.loc[region_ID]['OII3726_velocity','OII3729_velocity']     = fit['velocity']\n",
    "        fluxes.loc[region_ID]['OII3726_broadening','OII3729_broadening'] = fit['broadening']\n",
    "        \n",
    "        # correct for extinction\n",
    "        fluxes.loc[region_ID]['OII3726_FLUX'] /= extinction_mw26\n",
    "        fluxes.loc[region_ID]['OII3729_FLUX'] /= extinction_mw29\n",
    "\n",
    "        ebv,ebv_err = nebulae_catalogue.loc[region_ID][['EBV','EBV_ERR']]\n",
    "        \n",
    "        ext_int,ext_int_err = extinction(ebv,ebv_err,wavelength=3726)\n",
    "        fluxes.loc[region_ID]['OII3726_FLUX_CORR'] = fluxes.loc[region_ID]['OII3726_FLUX'] / ext_int\n",
    "        fluxes.loc[region_ID]['OII3726_FLUX_CORR_ERR'] = fluxes.loc[region_ID]['OII3726_FLUX_CORR']*np.sqrt((fluxes.loc[region_ID]['OII3726_FLUX_ERR']/fluxes.loc[region_ID]['OII3726_FLUX'])**2 + (ext_int_err/ext_int)**2)  \n",
    "\n",
    "        ext_int,ext_int_err = extinction(ebv,ebv_err,wavelength=3729)\n",
    "        fluxes.loc[region_ID]['OII3729_FLUX_CORR'] = fluxes.loc[region_ID]['OII3729_FLUX'] / ext_int\n",
    "        fluxes.loc[region_ID]['OII3729_FLUX_CORR_ERR'] = fluxes.loc[region_ID]['OII3729_FLUX_CORR']*np.sqrt((fluxes.loc[region_ID]['OII3729_FLUX_ERR']/fluxes.loc[region_ID]['OII3729_FLUX'])**2 + (ext_int_err/ext_int)**2)  \n",
    "\n",
    "    except:\n",
    "        print(f'error for {region_ID}')\n",
    "\n",
    "# save the table with the fluxes\n",
    "hdu = fits.BinTableHDU(fluxes,name='fluxes')\n",
    "hdu.writeto(basedir/'data'/output_folder/'fluxes'/f'{name}_OII_fluxes.fits',overwrite=True)\n",
    "\n",
    "# save the table with the fitted vector\n",
    "fit_table['OII3726'] *= u.erg/u.cm**2/u.s/u.AA\n",
    "fit_table['OII3729'] *= u.erg/u.cm**2/u.s/u.AA\n",
    "fit_table['fit'] *= u.erg/u.cm**2/u.s/u.AA\n",
    "hdu = fits.BinTableHDU(fit_table,name='fit')\n",
    "hdu.writeto(basedir/'data'/output_folder/'fit'/f'{name}_fit_SN1.fits',overwrite=True)\n",
    "\n",
    "# save the table with the line parameters\n",
    "hdu = fits.BinTableHDU(lines_params,name='line_params')\n",
    "hdu.writeto(basedir/'data'/output_folder/'line_params'/f'{name}_line_params.fits',overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all galaxies into one single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "tables = []\n",
    "for file in [x for x in (basedir/'data'/'data_v2p2'/'fluxes').iterdir() if x.stem.endswith('OII_fluxes')]:  \n",
    "    with fits.open(file) as hdul:\n",
    "        OII_fluxes = Table(hdul[1].data)    \n",
    "    tables.append(OII_fluxes)\n",
    "OII_fluxes = vstack(tables)\n",
    "\n",
    "doc = f'''this catalogue contains the [OII] fluxes for the objects in the nebula \n",
    "catalogue, measured from the SITELLE data. The nebulae masks are reprojected to \n",
    "the SITELLE data. Then the integrated spectra of each region is extracted and \n",
    "fitted with ORCS. We use the [NII] velocity from the nebulae catalogue as a \n",
    "prior for the fit. The flux ratio of the doublet is estimated based on the [SII] \n",
    "ratio with the help of pyneb. All fluxes are in [f]=1e-20 erg s-1 cm-2 AA-1 and \n",
    "corrected for Milky Way foreground extinction (with the extinction curve from \n",
    "O'Donnell (1994) and E(B-V) from Schlafly & Finkbeiner (2011)). The columns \n",
    "ending with _CORR are also corrected for internal extinction, based on the \n",
    "E(B-V) from the nebula catalogue. Based on the nebula catalogue v2p1. \n",
    "This catalogue was created with the following jupyter notebook:\n",
    "https://github.com/fschmnn/sitelle/blob/main/notebooks/Project3%20run%20ORBS.ipynb\n",
    "last update: {date.today().strftime(\"%b %d, %Y\")}\n",
    "'''\n",
    "\n",
    "primary_hdu = fits.PrimaryHDU()\n",
    "for i,comment in enumerate(doc.split('\\n')):\n",
    "    if i==0:\n",
    "        primary_hdu.header['COMMENT'] = comment\n",
    "    else:\n",
    "        primary_hdu.header[''] = comment\n",
    "table_hdu   = fits.BinTableHDU(OII_fluxes,name='[OII]')\n",
    "hdul = fits.HDUList([primary_hdu, table_hdu])\n",
    "hdul.writeto(basedir/'data'/'data_v2p2'/'Nebulae_Catalogue_v2p1_OII.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create emission line map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set region and make fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import find_contours\n",
    "from regions import PixCoord, PolygonPixelRegion\n",
    "import numpy as np \n",
    "\n",
    "def find_sky_region(mask,wcs):\n",
    "    '''create a region object from a mask and wcs\n",
    "    \n",
    "    Returns:\n",
    "    reg_pix : PixelRegion\n",
    "    reg_sky : SkyRegion\n",
    "    '''\n",
    "\n",
    "    mask[:,[0,-1]]=1\n",
    "    mask[[0,-1],:]=1\n",
    "\n",
    "    # find the contours around the image to use as vertices for the PixelRegion\n",
    "    contours = find_contours(mask,0.5,)\n",
    "    # we use the region with the most vertices\n",
    "    coords = max(contours,key=len)\n",
    "    #coords = np.concatenate(contours)\n",
    "\n",
    "    # the coordinates from find_counters are switched compared to astropy\n",
    "    reg_pix  = PolygonPixelRegion(vertices = PixCoord(*coords.T[::-1])) \n",
    "    reg_sky  = reg_pix.to_sky(wcs)\n",
    "    \n",
    "    return reg_pix, reg_sky\n",
    "\n",
    "\n",
    "reg_muse_pix, reg_muse_sky = find_sky_region(Halpha.mask.astype(int),wcs=Halpha.wcs)\n",
    "reg_muse_sitelle = reg_muse_sky.to_pixel(wcs)\n",
    "\n",
    "\n",
    "# define region in SITELLE pixel\n",
    "x,y,w,h = {'NGC0628': (1280,700,950,950), \n",
    "           'NGC2835': (1050,1050,900,900),\n",
    "           'NGC3351': (1080,1020,750,700), \n",
    "           'NGC4535': (1070,1020,600,800)\n",
    "          }.get(name)\n",
    "\n",
    "img = deepframe.data.copy()\n",
    "mask = np.zeros_like(img)\n",
    "mask[int(y-h/2):int(y+h/2),int(x-w/2):int(x+w/2)] = 1\n",
    "reg = np.nonzero(mask)\n",
    "mask[mask==0]=np.nan\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "norm = simple_norm(img,clip=False,percent=99)\n",
    "ax.imshow(img,norm=norm,origin='lower',cmap=plt.cm.Greys)\n",
    "ax.imshow(mask,origin='lower',vmax=1,alpha=0.5,cmap=plt.cm.Reds)\n",
    "reg_muse_sitelle.plot(ax=ax,ec='tab:red',label='MUSE')\n",
    "ax.set(xlim=[int(x-w/1.5),int(x+w/1.5)],ylim=[int(y-h/1.5),int(y+h/1.5)])\n",
    "ax.axis('off')\n",
    "#plt.savefig('NGC2835_deepframe.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gvar\n",
    "\n",
    "# constrain the velocity based on the distance/redshift\n",
    "# https://orcs.readthedocs.io/en/latest/script_example_fit_region.html?highlight=lines_in_region\n",
    "\n",
    "#orb.core.Logger(debug=False)\n",
    "velocity_gvar = gvar.gvar(velocity.value,150)\n",
    "broadening_gvar = gvar.gvar(10, 50)\n",
    "amp_ratio = amp_ratio_from_flux_ratio(OII3726,OII3729,1.4)\n",
    "\n",
    "linemaps = cube.fit_lines_in_region(reg[::-1],\n",
    "                         ['[OII]3726', '[OII]3729'],\n",
    "                         fmodel='sincgauss',\n",
    "                         pos_def=['1','1'],\n",
    "                         pos_cov=[velocity_gvar],\n",
    "                         amp_def=['1','1'],\n",
    "                         amp_guess=[1, amp_ratio],\n",
    "                         sigma_def=['1','1'],\n",
    "                         sigma_guess=[broadening_gvar,broadening_gvar],\n",
    "                         binning=2,\n",
    "                         snr_guess='auto',\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### determine wcs information \n",
    "\n",
    "first for binned image and reproject to MUSE\n",
    "\n",
    "look at https://astroalign.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reproject import reproject_exact, reproject_interp\n",
    "from astropy.wcs.utils import fit_wcs_from_points\n",
    "\n",
    "# read in the data\n",
    "flux_files = [x for x in (basedir/'maps'/f'{name}_linemap').iterdir() if x.stem.endswith('.flux')]\n",
    "with fits.open(flux_files[0]) as hdul:\n",
    "    OII_data = hdul[0].data\n",
    "    OII_header = hdul[0].header\n",
    "\n",
    "# find the x/y position in the new image\n",
    "xvalues = np.where(np.any(~np.isnan(OII_data),axis=0))\n",
    "xmin,xmax = np.min(xvalues),np.max(xvalues)\n",
    "yvalues = np.where(np.any(~np.isnan(OII_data),axis=1))\n",
    "ymin,ymax = np.min(yvalues),np.max(yvalues)\n",
    "xy = (np.array([xmin,xmin,xmax,xmax]),np.array([ymin,ymax,ymax,ymin]))\n",
    "\n",
    "# the equivalent SkyCoord form the old image\n",
    "coords = SkyCoord.from_pixel([x-w/2,x-w/2,x+w/2,x+w/2],[y-h/2,y+h/2,y+h/2,y-h/2],wcs=deepframe.wcs)\n",
    "ra,dec = ((coords.ra).to(u.degree).value,(coords.dec).to(u.degree).value)\n",
    "radec = SkyCoord(ra, dec, unit=(u.deg, u.deg))\n",
    "\n",
    "# calculate the wcs information for the linemap\n",
    "OII_wcs = fit_wcs_from_points(xy,radec,'center')\n",
    "\n",
    "# reproject to MUSE \n",
    "OII_reprojected = reproject_exact((OII_data,OII_wcs),Halpha.meta,return_footprint=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare [OII] image with Halpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fig = plt.figure(figsize=(9,3))\n",
    "ax1=fig.add_subplot(131,projection=Halpha.wcs)\n",
    "ax2=fig.add_subplot(132,projection=Halpha.wcs)\n",
    "ax3=fig.add_subplot(133,projection=Halpha.wcs)\n",
    "'''\n",
    "\n",
    "fig,(ax1,ax2,ax3) = plt.subplots(ncols=3,figsize=(9,3))\n",
    "\n",
    "img = deepframe.data.copy()\n",
    "mask = np.zeros_like(img)\n",
    "mask[int(y-h/2):int(y+h/2),int(x-w/2):int(x+w/2)] = 1\n",
    "mask[mask==0]=np.nan\n",
    "\n",
    "norm = simple_norm(img,clip=False,percent=99)\n",
    "ax1.imshow(img,norm=norm,origin='lower',cmap=plt.cm.Greys)\n",
    "ax1.imshow(mask,origin='lower',vmax=1,alpha=0.5,cmap=plt.cm.Reds)\n",
    "reg_muse_sitelle.plot(ax=ax1,ec='tab:red',label='MUSE')\n",
    "ax1.axis('off')\n",
    "ax1.set_title('SITELLE deepframe')\n",
    "\n",
    "norm = simple_norm(OII_reprojected,clip=False,percent=98)\n",
    "ax2.imshow(OII_reprojected,origin='lower',norm=norm,cmap=plt.cm.Blues)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('SITELLE [OII]3727')\n",
    "\n",
    "norm = simple_norm(Halpha.data,clip=False,percent=98)\n",
    "ax3.imshow(Halpha.data,origin='lower',norm=norm,cmap=plt.cm.Reds)\n",
    "ax3.axis('off')\n",
    "ax3.set_title(r'MUSE H$\\alpha$')\n",
    "\n",
    "'''\n",
    "for ax in [ax1,ax2,ax3]:\n",
    "    ax.coords[0].set_ticks_visible(False)\n",
    "    ax.coords[0].set_ticklabel_visible(False)\n",
    "    ax.coords[1].set_ticks_visible(False)\n",
    "    ax.coords[1].set_ticklabel_visible(False)\n",
    "'''\n",
    "plt.tight_layout()\n",
    "plt.savefig(basedir/'reports'/name/f'{name}_SITELLE_map.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "determine wcs information of binned cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the x/y position in the new image\n",
    "xvalues = np.where(np.any(~np.isnan(OII_data),axis=0))\n",
    "xmin,xmax = np.min(xvalues),np.max(xvalues)\n",
    "yvalues = np.where(np.any(~np.isnan(OII_data),axis=1))\n",
    "ymin,ymax = np.min(yvalues),np.max(yvalues)\n",
    "xy = (np.array([0,0,xmax-xmin,xmax-xmin]),np.array([0,ymax-ymin,ymax-ymin,0]))\n",
    "\n",
    "# the equivalent SkyCoord form the old image\n",
    "coords = SkyCoord.from_pixel([x-w/2,x-w/2,x+w/2,x+w/2],[y-h/2,y+h/2,y+h/2,y-h/2],wcs=deepframe.wcs)\n",
    "ra,dec = ((coords.ra).to(u.degree).value,(coords.dec).to(u.degree).value)\n",
    "radec = SkyCoord(ra, dec, unit=(u.deg, u.deg))\n",
    "\n",
    "# calculate the wcs information for the linemap\n",
    "OII_cutout_wcs = fit_wcs_from_points(xy,radec,'center')\n",
    "OII_cutout = OII_data[ymin:ymax,xmin:xmax]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save to new fits file\n",
    "\n",
    "first the reprojected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the primary header\n",
    "primary_header = fits.Header()\n",
    "primary_hdu = fits.PrimaryHDU(header=primary_header)\n",
    "hdul = fits.HDUList([primary_hdu]) \n",
    "\n",
    "for line in ['3726','3729']:\n",
    "    flux_file = basedir/'maps'/f'{name}_linemap'/f'{name}_SN1.LineMaps.map.{line}.2x2.flux.fits'\n",
    "    OII_data = fits.getdata(flux_file)\n",
    "    error_file = basedir/'maps'/f'{name}_linemap'/f'{name}_SN1.LineMaps.map.{line}.2x2.flux-err.fits'\n",
    "    OII_error = fits.getdata(error_file)\n",
    "    \n",
    "    # create a new header\n",
    "    header = Halpha.wcs.to_header()\n",
    "    header['BITPIX'] = (-32,'array data type')\n",
    "    header.insert(0,('FILETYPE',f'Map flux {line}'))\n",
    "    \n",
    "    print(f'reprojecting {line} flux')\n",
    "    OII_reprojected = reproject_exact((OII_data,OII_wcs),Halpha.meta,return_footprint=False)\n",
    "    hdu = fits.ImageHDU(data=OII_reprojected,header=header,name=f'OII{line}_FLUX')\n",
    "    hdul.append(hdu)\n",
    "    \n",
    "    print(f'reprojecting {line} flux err')\n",
    "    OII_error_reprojected = reproject_exact((OII_error,OII_wcs),Halpha.meta,return_footprint=False)\n",
    "    header['FILETYPE'] = f'Map flux error {line}'\n",
    "    hdu = fits.ImageHDU(data=OII_error_reprojected,header=header,name=f'OII{line}_FLUX_ERR')\n",
    "    hdul.append(hdu)\n",
    "\n",
    "hdul.writeto(basedir/'data'/'maps'/f'{name}_OII_map_reprojected.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now save the cutout with the correct wcs information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the primary header\n",
    "primary_header = fits.Header()\n",
    "primary_hdu = fits.PrimaryHDU(header=primary_header)\n",
    "hdul = fits.HDUList([primary_hdu]) \n",
    "\n",
    "for line in ['3726','3729']:\n",
    "    flux_file = basedir/'maps'/f'{name}_linemap'/f'{name}_SN1.LineMaps.map.{line}.2x2.flux.fits'\n",
    "    OII_data = fits.getdata(flux_file)\n",
    "    error_file = basedir/'maps'/f'{name}_linemap'/f'{name}_SN1.LineMaps.map.{line}.2x2.flux-err.fits'\n",
    "    OII_error = fits.getdata(error_file)\n",
    "    \n",
    "    # create a new header\n",
    "    header = OII_cutout_wcs.to_header()\n",
    "    header['BITPIX'] = (-32,'array data type')\n",
    "    header.insert(0,('FILETYPE',f'Map flux {line}'))\n",
    "    \n",
    "    print(f'reprojecting {line} flux')\n",
    "    OII_data = OII_data[ymin:ymax,xmin:xmax]\n",
    "    hdu = fits.ImageHDU(data=OII_data,header=header,name=f'OII{line}_FLUX')\n",
    "    hdul.append(hdu)\n",
    "    \n",
    "    print(f'reprojecting {line} flux err')\n",
    "    OII_error = OII_error[ymin:ymax,xmin:xmax]\n",
    "    header['FILETYPE'] = f'Map flux error {line}'\n",
    "    hdu = fits.ImageHDU(data=OII_error,header=header,name=f'OII{line}_FLUX_ERR')\n",
    "    hdul.append(hdu)\n",
    "\n",
    "hdul.writeto(basedir/'data'/'maps'/f'{name}_OII_map.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OIId, OIIh = fits.getdata(basedir/'data'/'maps'/f'{name}_SITELLE.fits','OII3726_FLUX',header=True)\n",
    "OIIrd, OIIrh = fits.getdata(basedir/'data'/'maps'/f'{name}_SITELLE_reprojected.fits','OII3726_FLUX',header=True)\n",
    "\n",
    "fig = plt.figure(figsize=(9,3))\n",
    "ax1=fig.add_subplot(131,projection=WCS(OIIh))\n",
    "ax2=fig.add_subplot(132,projection=WCS(OIIrh))\n",
    "\n",
    "norm = simple_norm(OIId,clip=False,percent=99)\n",
    "ax1.imshow(OIId,norm=norm,cmap=plt.cm.Greys)\n",
    "ax1.set_title('[OII]3727 cutout')\n",
    "\n",
    "norm = simple_norm(OIIrd,clip=False,percent=99)\n",
    "ax2.imshow(OIIrd,norm=norm,cmap=plt.cm.Greys)\n",
    "ax2.set_title('[OII]3727 reprojected')\n",
    "\n",
    "'''\n",
    "for ax in [ax1,ax2,ax3]:\n",
    "    ax.coords[0].set_ticks_visible(False)\n",
    "    ax.coords[0].set_ticklabel_visible(False)\n",
    "    ax.coords[1].set_ticks_visible(False)\n",
    "    ax.coords[1].set_ticklabel_visible(False)\n",
    "'''\n",
    "\n",
    "ax3=fig.add_subplot(133,projection=Halpha.wcs)\n",
    "norm = simple_norm(Halpha.data,clip=False,percent=99)\n",
    "ax3.imshow(Halpha.data,norm=norm,cmap=plt.cm.Greys)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,9))\n",
    "ax=fig.add_subplot(111,projection=Halpha.wcs)\n",
    "\n",
    "\n",
    "norm = simple_norm(OIIrd,clip=False,percent=99)\n",
    "ax.imshow(OIIrd,norm=norm,cmap=plt.cm.Greys)\n",
    "norm = simple_norm(Halpha.data,clip=False,percent=99)\n",
    "ax.imshow(Halpha.data,norm=norm,cmap=plt.cm.Reds,alpha=0.5)\n",
    "plt.savefig(basedir/'reports'/name/f'{name}_SITELLE_MUSE_alignment.png',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_table(table,**kwargs):\n",
    "    '''filter a table with the given keyword arguments'''\n",
    "    \n",
    "    for k,v in kwargs.items():\n",
    "        if k in table.colnames:\n",
    "            table = table[np.isin(table[k],v)]\n",
    "        else:\n",
    "            raise ValueError(f'WARNING: invalid column name {k}')\n",
    "    return table\n",
    "\n",
    "sitelle_all = ['NGC0628','NGC1087','NGC1300','NGC2835','NGC3351','NGC3627',\n",
    "               'NGC4254','NGC4303', 'NGC4321','NGC4535','NGC5068']\n",
    "sitelle_observed = ['NGC0628','NGC2835','NGC3351','NGC4535']\n",
    "\n",
    "name = 'NGC0628'\n",
    "\n",
    "with fits.open(basedir/'data'/'Nebulae_Catalogue_DR2_native_with_OII.fits') as hdul:\n",
    "    nebulae = Table(hdul[1].data)\n",
    "nebulae['SkyCoord'] = SkyCoord(nebulae['cen_ra']*u.degree,nebulae['cen_dec']*u.degree)\n",
    "\n",
    "with fits.open(basedir/'data'/'fit'/f'{name}_fit_SN1.fits') as hdul:\n",
    "    fit_table = Table(hdul[1].data)\n",
    "fit_table.add_index('region_ID')\n",
    "\n",
    "with fits.open(basedir/'data'/'line_params'/f'{name}_line_params.fits') as hdul:\n",
    "    line_params = Table(hdul[1].data)\n",
    "line_params.add_index('region_ID')\n",
    "\n",
    "# this table is already part of nebulae but here it is anyways\n",
    "with fits.open(basedir/'data'/f'{name}_OII_fluxes.fits') as hdul:\n",
    "    fluxes = Table(hdul[1].data)\n",
    "fluxes.add_index('region_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot linemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3) = plt.subplots(ncols=3,figsize=(10,4))\n",
    "\n",
    "for name,ax in zip(['NGC0628','NGC2835','NGC3351'],[ax1,ax2,ax3]):\n",
    "    with fits.open(basedir/'..'/'sitelle'/'data'/'maps'/f'{name}_OII_map.fits') as hdul:\n",
    "        OII = hdul['OII3726_FLUX'].data\n",
    "        OII_header = hdul['OII3726_FLUX'].header\n",
    "    \n",
    "    norm = simple_norm(OII,clip=False,percent=98)\n",
    "    ax.imshow(OII,norm=norm,origin='lower',cmap=plt.cm.Greys)\n",
    "    ax.set_title(name)\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we look at a single spectrum\n",
    "def plot_spectrum(axis,spectrum,fit=np.array([]),fit_err=np.array([])):\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,3))\n",
    "    ax  = fig.add_subplot(111)\n",
    "\n",
    "    ax.plot(axis, spectrum, label='spectrum')\n",
    "    if len(fit)>0:\n",
    "        ax.plot(axis, fit, label='Fitted spectrum')\n",
    "        if len(fit_err)>0:\n",
    "            ax.fill_between(axis,fit - fit_err, fit + fit_err, color='tab:orange',alpha=0.2)\n",
    "    \n",
    "    ax.set(xlabel=r'wavenumber / cm$^{-1}$',\n",
    "           xlim=(26000,27500))\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "region_ID = 120\n",
    "axis     = fit_table.loc[region_ID]['axis']\n",
    "spectrum = fit_table.loc[region_ID]['spectrum']\n",
    "fit      = fit_table.loc[region_ID]['fit']\n",
    "\n",
    "plot_spectrum(axis,spectrum,fit=fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import datetime\n",
    "\n",
    "def multi_page_spectra(sample,spectra,position=26838,filename=None,nrows=5,ncols=4):\n",
    "    '''Plot multiple cutouts with the positoin of the clusters\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    sample : list\n",
    "        list of region_IDs\n",
    "    spectra : astropy table\n",
    "        table with index region_ID and columns for spectra\n",
    "    position : float\n",
    "        wavenumber that is used as the centre of the spectrum\n",
    "    filename : string/pathlib.Path\n",
    "        save the spectra to this file\n",
    "    '''\n",
    "    \n",
    "    print(f'plotting {len(sample)} spectra')\n",
    "    width = 8.27\n",
    "    N = len(sample)\n",
    "    Npage = nrows*ncols-1      # number of subplots per page\n",
    "    position = 26752.202073977973\n",
    "    \n",
    "    with PdfPages(filename.with_suffix('.pdf')) as pdf:\n",
    "        \n",
    "        for i in range(int(np.ceil(N/Npage))):\n",
    "            print(f'working on page {i+1}')\n",
    "            \n",
    "            sub_sample = sample[i*Npage:(i+1)*Npage]\n",
    "        \n",
    "            fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(11.7,8.3))\n",
    "            axes_iter = iter(axes.flatten())\n",
    "\n",
    "            for region_ID in sub_sample:  \n",
    "\n",
    "                ax = next(axes_iter)\n",
    "                axis,spectrum,OII3726,OII3729,fit_total = spectra.loc[region_ID][['axis','spectrum','OII3726','OII3729','fit']]\n",
    "                ax.plot(axis,spectrum,label='spectrum',color='black')\n",
    "                ax.plot(axis, fit_total, label='fit', ls='--',lw=0.8, c='grey')\n",
    "                ax.plot(axis,OII3726,label='OII3726',ls='--',lw=0.8,color='tab:blue')\n",
    "                ax.plot(axis,OII3729,label='OII3729',ls='--',lw=0.8,color='tab:red')\n",
    "                ax.set_xticks(np.round(np.linspace(position-300,position+300,5)))\n",
    "                ax.set_yticklabels([])\n",
    "                \n",
    "                ax.set(xlim=[position-400,position+400],xlabel=r'wavenumber / cm$^{-1}$',)    \n",
    "                t = ax.text(0.03,0.78,f'region_ID: {region_ID}', transform=ax.transAxes,color='black',fontsize=8)\n",
    "                t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "                \n",
    "            plt.subplots_adjust(wspace=-0.0, hspace=0)\n",
    "           \n",
    "            h,l = fig.axes[0].get_legend_handles_labels()\n",
    "            ax = next(axes_iter)\n",
    "            ax.axis('off')\n",
    "            ax.legend(h,l,fontsize=7,loc='center left',frameon=False)        \n",
    "\n",
    "            # only the last page has subplots that need to be removed\n",
    "            if i == int(np.ceil(N/Npage))-1:\n",
    "                for i in range(nrows*ncols-len(sub_sample)-1):\n",
    "                    # remove the empty axes at the bottom\n",
    "                    ax = next(axes_iter)\n",
    "                    ax.axis('off')    \n",
    "        \n",
    "            pdf.savefig()  # saves the current figure into a pdf page\n",
    "            plt.close()\n",
    "          \n",
    "\n",
    "fluxes['SNR'] = fluxes['OII3726_FLUX_CORR']/fluxes['OII3726_FLUX_CORR_ERR']\n",
    "fluxes.sort('SNR',reverse=True)\n",
    "sample = fluxes[fluxes['SNR']>3]['region_ID']\n",
    "print(len(sample))\n",
    "        \n",
    "multi_page_spectra(sample,fit_table,position=line_params['pos_OII3726'].mean(),\n",
    "                   filename=basedir/'reports'/name/f'{name}_spectra.pdf',\n",
    "                   nrows=6,ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare surface brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(6,4))\n",
    "\n",
    "catalogue = filter_table(nebulae,gal_name=sitelle_observed)\n",
    "\n",
    "sbOII=1e-20*catalogue['OII3726_FLUX_CORR']*u.erg/u.s/u.cm**2/(catalogue['region_area']*0.2**2 *u.arcsec**2)\n",
    "sbOIII=1e-20*catalogue['OIII5006_FLUX_CORR']*u.erg/u.s/u.cm**2/(catalogue['region_area']*0.2**2 *u.arcsec**2)\n",
    "sbHA=1e-20*catalogue['HA6562_FLUX_CORR']*u.erg/u.s/u.cm**2/(catalogue['region_area']*0.2**2 *u.arcsec**2)\n",
    "\n",
    "logbins = np.logspace(-17.5,-14.5,40)\n",
    "ax.hist(sbHA.value,bins=logbins,alpha=0.6,label=r'H$\\alpha$')\n",
    "ax.hist(sbOII.value,bins=logbins,alpha=0.6,label='[OII]')\n",
    "ax.hist(sbOIII.value,bins=logbins,alpha=0.6,label='[OIII]')\n",
    "\n",
    "#ax.hist(sbHA.value,bins=np.linspace(1e-17,5e-16,40),alpha=0.6,label=r'H$\\alpha$')\n",
    "ax.set(xlabel='surface brightness / (erg/s/cm2/arcsec2)',xscale='log')\n",
    "ax.legend(fontsize=10)\n",
    "#plt.savefig(basedir/'reports'/name/f'{name}_surface_brightness.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the proposal we also plot the R23 diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue = nebulae\n",
    "\n",
    "# check ratios for NII6548 and OIII4959\n",
    "catalogue['N2']  = 1.2*catalogue['NII6583_FLUX_CORR'] / catalogue['HB4861_FLUX_CORR']\n",
    "catalogue['R2']  = (catalogue['OII3726_FLUX_CORR']+catalogue['OII3729_FLUX_CORR']) / catalogue['HB4861_FLUX_CORR']\n",
    "catalogue['R3']  = (1.2*catalogue['OIII5006_FLUX']) / catalogue['HB4861_FLUX_CORR']\n",
    "catalogue['R23'] = catalogue['R2'] + catalogue['R3']\n",
    "catalogue['R23'] = np.log10((2.4*catalogue['OII3726_FLUX_CORR']+1.3*catalogue['OIII5006_FLUX_CORR'])/catalogue['HB4861_FLUX_CORR'])\n",
    "\n",
    "proposed = filter_table(catalogue,gal_name=sitelle_all)\n",
    "observed = filter_table(catalogue,gal_name=sitelle_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OII7319_detection = observed['OII7319_FLUX_CORR']/observed['OII7319_FLUX_CORR_ERR']>7\n",
    "OII3726_detection = observed['OII3726_FLUX_CORR']/observed['OII3726_FLUX_CORR_ERR']>3\n",
    "OII7319_detection_prop = proposed['OII7319_FLUX_CORR']/proposed['OII7319_FLUX_CORR_ERR']>7\n",
    "\n",
    "print(f'[OII]7319 detections: {np.sum(OII7319_detection)} (observed)')\n",
    "print(f'[OII]7319 detections: {np.sum(OII7319_detection_prop)} (proposed)')\n",
    "print(f'[OII]3726 detections: {np.sum(OII3726_detection)}')\n",
    "print(f'combined detections: {np.sum(OII7319_detection&OII3726_detection)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3)=plt.subplots(ncols=3,figsize=(two_column,two_column/2.9))\n",
    "\n",
    "sbOII7319_obs  =1e-20*observed['OII7319_FLUX_CORR']*u.erg/u.s/u.cm**2/(observed['region_area']*0.2**2 *u.arcsec**2)\n",
    "sbOII7319_prop =1e-20*proposed['OII7319_FLUX_CORR']*u.erg/u.s/u.cm**2/(proposed['region_area']*0.2**2 *u.arcsec**2)\n",
    "\n",
    "sbOII3726_obs  =1e-20*observed['OII3726_FLUX_CORR']*u.erg/u.s/u.cm**2/(observed['region_area']*0.2**2 *u.arcsec**2)\n",
    "\n",
    "\n",
    "tmp = observed[observed['OII3726_FLUX_CORR']/observed['OII3726_FLUX_CORR_ERR']>3]\n",
    "\n",
    "sc=ax1.scatter(tmp['met_scal'],tmp['R23'],c=tmp['logq_D91'],s=4,cmap=plt.cm.plasma_r)\n",
    "fig.colorbar(sc,label=r'ionization parameter $q$',ax=ax1)\n",
    "ax1.set(xlim=[8.1,8.7],ylim=[-0.5,1.],xlabel=r'$12+\\log(\\mathrm{O}/\\mathrm{H})$',ylabel=r'$\\log\\,R_{23}$')\n",
    "\n",
    "\n",
    "logbins = np.logspace(-19,-15,30)\n",
    "# np.linspace(1e-18,5e-17,40)\n",
    "ax2.hist(sbOII7319_prop.value,bins=logbins,color='tab:red',alpha=0.8,label='proposed')\n",
    "ax2.hist(sbOII7319_obs.value,bins=logbins,color='tab:blue',alpha=0.8,label='observed')\n",
    "ax2.set(xlabel=r'$\\Sigma$ / (erg s$^{-1}$ cm$^{-2}$ arcsec$^{-2}$)',xscale='log',ylim=[0,800])\n",
    "ax2.set_title('MUSE auroral [OII]7319')\n",
    "ax2.legend(fontsize=8)\n",
    "\n",
    "ax3.hist(sbOII3726_obs.value,bins=logbins,alpha=0.8,color='tab:blue')\n",
    "#for n in np.unique(observed['gal_name']):\n",
    "#    ax3.hist(sbOII3726_obs[observed['gal_name']==n].value,bins=logbins,alpha=0.5,label=n)\n",
    "#ax3.legend()\n",
    "ax3.set(xlabel=r'$\\Sigma$ / (erg s$^{-1}$ cm$^{-2}$ arcsec$^{-2}$)',xscale='log',ylim=[0,800])\n",
    "ax3.set_title('SITELLE [OII]3727')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(basedir/'reports'/f'surface_brightness.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OH(R2,R3,N2):\n",
    "    \n",
    "    # upper branch\n",
    "    if N2>-0.6:\n",
    "        a1,a2,a3,a4,a5,a6=8.589,0.022,0.399,-0.137,0.164,0.589\n",
    "    else:\n",
    "        a1,a2,a3,a4,a5,a6=7.932,0.944,0.695,0.970,-0.291,-0.019\n",
    "    x = a1+a2*np.log10(R3/R2)+a3*np.log10(N2)+(a4+a5*np.log10(R3/R2)+a6*np.log10(N2))*np.log10(R2)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distribution of surface brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbHA6562 =1e-20*proposed['HA6562_FLUX_CORR']*u.erg/u.s/u.cm**2/(proposed['region_area']*0.2**2 *u.arcsec**2)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(6,4))\n",
    "\n",
    "logbins = np.logspace(-17,-14,30)\n",
    "ax.hist(sbHA6562.value,bins=logbins,color='tab:red',alpha=0.8,label='proposed')\n",
    "ax.set(xlabel=r'$\\Sigma$ / (erg s$^{-1}$ cm$^{-2}$ arcsec$^{-2}$)',xscale='log')\n",
    "ax.set_title(r'H$\\alpha$ surface brightness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Compare linemaps with extracted spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name = 'NGC2835'\n",
    "\n",
    "data_raw = Path('a:')\n",
    "\n",
    "# we read in all necessary files to measure the flux from the region\n",
    "with fits.open(basedir/'data'/'Nebulae_Catalogue_DR2_native_with_OII.fits') as hdul:\n",
    "    nebulae_with_OII = Table(hdul[1].data)\n",
    "nebulae_with_OII = nebulae_with_OII[nebulae_with_OII['gal_name']==name]\n",
    "nebulae_with_OII.add_index('region_ID')\n",
    "\n",
    "mask_file = data_raw/'MUSE_DR2'/'Nebulae catalogue'/'spatial_masks'/f'{name}_HIIreg_mask.fits'.format(name) \n",
    "with fits.open(mask_file) as hdul:\n",
    "    # -1 because the masks start with 1 instead of 0\n",
    "    nebulae_mask = NDData(hdul[0].data-1,meta=hdul[0].header,wcs=WCS(hdul[0].header))\n",
    "    nebulae_mask.data[nebulae_mask.data==-1] = np.nan\n",
    "\n",
    "# read in the data\n",
    "flux_file = basedir/'data'/'maps'/f'{name}_OII_map_reprojected.fits'\n",
    "with fits.open(flux_file) as hdul:\n",
    "    OII_reprojected = hdul['OII3726_FLUX'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from dust_extinction.parameter_averages import O94, CCM89\n",
    "\n",
    "# EBV of the galaxies\n",
    "EBV = {'IC5332': 0.015,'NGC0628': 0.062,'NGC1087': 0.03,'NGC1300': 0.026,'NGC1365': 0.018,\n",
    "       'NGC1385': 0.018,'NGC1433': 0.008,'NGC1512': 0.009,'NGC1566': 0.008,'NGC1672': 0.021,\n",
    "       'NGC2835': 0.089,'NGC3351': 0.024,'NGC3627': 0.037,'NGC4254': 0.035,'NGC4303': 0.02,\n",
    "       'NGC4321': 0.023,'NGC4535': 0.017,'NGC5068': 0.091,'NGC7496': 0.008}\n",
    "\n",
    "extinction_model = CCM89(Rv=3.1)\n",
    "extinction_mw26  = extinction_model.extinguish(3626*u.angstrom,Ebv=0.5*EBV[name])\n",
    "\n",
    "flux_from_map = []\n",
    "for region_ID in nebulae_with_OII['region_ID']:\n",
    "    mask = nebulae_mask.data==region_ID\n",
    "    OII_flux = np.sum(OII_reprojected[mask])\n",
    "    flux_from_map.append(OII_flux)\n",
    "\n",
    "flux_from_map = 1e20*np.array(flux_from_map)/extinction_mw26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "criteria = nebulae_with_OII['OII3726_FLUX_CORR']>3*nebulae_with_OII['OII3726_FLUX_CORR_ERR']\n",
    "x,y = nebulae_with_OII['OII3726_FLUX'][criteria],flux_from_map[criteria]\n",
    "x,y = x[~np.isnan(x) & ~np.isnan(y)], y[~np.isnan(x) & ~np.isnan(y)]\n",
    "y/=10.30570988180577\n",
    "\n",
    "nbins = 20\n",
    "lim   = np.array([3.5,7])\n",
    "\n",
    "\n",
    "# definitions for the axes\n",
    "left, width = 0.1, 0.65\n",
    "bottom, height = 0.1, 0.65\n",
    "spacing = 0.005\n",
    "\n",
    "rect_scatter = [left, bottom, width, height]\n",
    "rect_histx = [left, bottom + height + spacing, width, 0.2]\n",
    "rect_histy = [left + width + spacing, bottom, 0.2, height]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax = fig.add_axes(rect_scatter)\n",
    "ax_histx = fig.add_axes(rect_histx, sharex=ax)\n",
    "ax_histy = fig.add_axes(rect_histy, sharey=ax)\n",
    "\n",
    "ax_histx.tick_params(axis=\"x\", labelbottom=False)\n",
    "ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
    "\n",
    "# the scatter plot:\n",
    "ax.scatter(x,y)\n",
    "ax.plot(10**lim,10**lim,color='black')\n",
    "ax_histx.hist(x, bins=np.logspace(*lim,nbins))\n",
    "ax_histy.hist(y, bins=np.logspace(*lim,nbins), orientation='horizontal')\n",
    "\n",
    "ax.set(xlim=10**lim,ylim=10**lim,xscale='log',yscale='log',\n",
    "       xlabel='OII3727 from Spectra',ylabel='OII 3727 from map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### reprojected vs native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name = 'NGC0628'\n",
    "\n",
    "# read in the data\n",
    "flux_file = basedir/'data'/'maps'/f'{name}_OII_map_reprojected.fits'\n",
    "with fits.open(flux_file) as hdul:\n",
    "    reprojected = NDData(data=hdul['OII3726_FLUX'].data,\n",
    "                    meta=hdul['OII3726_FLUX'].header,\n",
    "                    wcs=WCS(hdul['OII3726_FLUX'].header))\n",
    "    \n",
    "# read in the data\n",
    "flux_file = basedir/'data'/'maps'/f'{name}_OII_map.fits'\n",
    "with fits.open(flux_file) as hdul:\n",
    "    native = NDData(data=hdul['OII3726_FLUX'].data,\n",
    "                    meta=hdul['OII3726_FLUX'].header,\n",
    "                    wcs=WCS(hdul['OII3726_FLUX'].header))\n",
    "    \n",
    "# we read in all necessary files to measure the flux from the region\n",
    "with fits.open(basedir/'data'/'Nebulae_Catalogue_DR2_native_with_OII.fits') as hdul:\n",
    "    nebulae = Table(hdul[1].data)\n",
    "nebulae['SkyCoord'] = SkyCoord(nebulae['cen_ra']*u.degree,nebulae['cen_dec']*u.degree)\n",
    "nebulae = nebulae[nebulae['gal_name']==name]\n",
    "nebulae.add_index('region_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from photutils import aperture_photometry, SkyCircularAperture\n",
    "\n",
    "apertures = SkyCircularAperture(nebulae['SkyCoord'],2*u.arcsecond)\n",
    "\n",
    "flux_native = aperture_photometry(native,apertures)['aperture_sum']\n",
    "flux_reprojected = aperture_photometry(reprojected,apertures)['aperture_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.nanmean(flux_reprojected/flux_native)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot regions over OII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from region import Regions   \n",
    "muse_regions = Regions(mask=nebulae_mask.data,projection=nebulae_mask.meta,bkg=-1)\n",
    "\n",
    "muse_regions.plot(image=OII_reprojected,regions=False,\n",
    "                     filename=basedir/'reports'/name/f'{name}_OII_regions.png',\n",
    "                     xlabel='R.A.',ylabel='Dec.', \n",
    "                     percent=99.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with SIGNALS survey\n",
    "\n",
    "#### Calculate the line ratios they use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import find_contours\n",
    "from regions import PixCoord, PolygonPixelRegion\n",
    "\n",
    "def filter_table(table,**kwargs):\n",
    "    '''filter a table with the given keyword arguments'''\n",
    "    \n",
    "    for k,v in kwargs.items():\n",
    "        if k in table.colnames:\n",
    "            table = table[np.isin(table[k],v)]\n",
    "        else:\n",
    "            raise ValueError(f'WARNING: invalid column name {k}')\n",
    "    return table\n",
    "\n",
    "def find_sky_region(mask,wcs):\n",
    "    '''create a region object from a mask and wcs\n",
    "    \n",
    "    Returns:\n",
    "    reg_pix : PixelRegion\n",
    "    reg_sky : SkyRegion\n",
    "    '''\n",
    "\n",
    "    mask[:,[0,-1]]=1\n",
    "    mask[[0,-1],:]=1\n",
    "\n",
    "    # find the contours around the image to use as vertices for the PixelRegion\n",
    "    contours = find_contours(mask,0.5,)\n",
    "    # we use the region with the most vertices\n",
    "    coords = max(contours,key=len)\n",
    "    #coords = np.concatenate(contours)\n",
    "\n",
    "    # the coordinates from find_counters are switched compared to astropy\n",
    "    reg_pix  = PolygonPixelRegion(vertices = PixCoord(*coords.T[::-1])) \n",
    "    reg_sky  = reg_pix.to_sky(wcs)\n",
    "    \n",
    "    return reg_pix, reg_sky\n",
    "\n",
    "reg_muse_pix, reg_muse_sky = find_sky_region(Halpha.mask.astype(int),wcs=Halpha.wcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if name!='NGC0628':\n",
    "    raise ValueError(f'current Galaxy is {name} and not NGC0628')\n",
    "with open(basedir/'SIGNALS'/'columns.txt') as f:\n",
    "    txt = f.read()\n",
    "names = txt.split('\\n')\n",
    "#with fits.open(basedir/'SIGNALS'/'NGC628_catalog.fits') as hdul:\n",
    "#    signals = Table(hdul[0].data,names=names)\n",
    "with fits.open(basedir/'SIGNALS'/'NGC628_catalog_WCS_corr.fits') as hdul:\n",
    "    signals = Table(hdul[0].data,names=names)\n",
    "    \n",
    "with fits.open(basedir/'data_v2p1'/'Nebulae_catalogue_v2.fits' ) as hdul:\n",
    "    nebulae_catalogue = Table(hdul[1].data)\n",
    "nebulae_catalogue = nebulae_catalogue[nebulae_catalogue['gal_name']==name]\n",
    "nebulae_catalogue['SkyCoord'] = SkyCoord(nebulae_catalogue['cen_ra']*u.degree,nebulae_catalogue['cen_dec']*u.degree)\n",
    "with fits.open(basedir/'data_v2p1'/'fluxes'/'NGC0628_OII_fluxes.fits') as hdul:\n",
    "    OII_fluxes = Table(hdul[1].data)\n",
    "nebulae_catalogue = join(nebulae_catalogue,OII_fluxes,keys=['gal_name','region_ID'])\n",
    "    \n",
    "signals['SkyCoord'] = SkyCoord(signals['RA']*u.degree,signals['DEC']*u.degree)\n",
    "signals['HA_FLUX']  = signals['HA_FLUX_CORR'] / (4*np.pi*(9.552*u.Mpc).to(u.cm)**2)\n",
    "signals['NII6583_FLUX'] = signals['HA_FLUX']* np.exp(signals['log(NII6583/HA)'])\n",
    "signals['OII3727_FLUX'] = signals['NII6583_FLUX']* np.exp(signals['log(OII3727/NII6583)'])\n",
    "signals['OIII5007_FLUX'] = signals['NII6583_FLUX']* np.exp(signals['log(OIII5007/NII6583)'])\n",
    "signals['in_frame'] = reg_muse_sky.contains(signals['SkyCoord'],Halpha.wcs)\n",
    "\n",
    "def calculate_ratios(tbl):\n",
    "    '''\n",
    "    caculate the signals line ratios for the MUSE nebulae catalogue\n",
    "    \n",
    "    'log(NII6583/HA)',\n",
    "    'log(SII6716+6731/HA)',\n",
    "    'log(SII6716+6731/NII6583)',\n",
    "    'log(OIII5007/HB)',\n",
    "    'log(OII3727/HB)',\n",
    "    'log(OII3727+OII5007/HB)',\n",
    "    'log(OIII5007/OII3727 )',\n",
    "    'log(OIII5007/NII6583 )',\n",
    "    'log(OII3727/NII6583)',\n",
    "    'log(SII6717/SII6731)'\n",
    "    ''' \n",
    "    \n",
    "    with np.errstate(divide='ignore'):\n",
    "        tbl['NII6583/HA'] = np.log10(tbl['NII6583_FLUX_CORR']/tbl['HA6562_FLUX_CORR'])\n",
    "        tbl['SII6716+6731/HA'] = np.log10((tbl['SII6716_FLUX_CORR']+tbl['SII6730_FLUX_CORR'])/tbl['HA6562_FLUX_CORR'])\n",
    "        tbl['SII6716+6731/NII6583'] = np.log10((tbl['SII6716_FLUX_CORR']+tbl['SII6730_FLUX_CORR'])/tbl['NII6583_FLUX_CORR'])\n",
    "        tbl['OIII5007/HB'] = np.log10(tbl['OIII5006_FLUX_CORR']/tbl['HB4861_FLUX_CORR'])\n",
    "        tbl['OIII5007/NII6583'] = np.log10(tbl['OIII5006_FLUX_CORR']/tbl['NII6583_FLUX_CORR'])\n",
    "        tbl['SII6717/SII6731'] = np.log10(tbl['SII6716_FLUX_CORR']/tbl['SII6730_FLUX_CORR'])    \n",
    "        tbl['SII6717/SII6731'] = np.log10(tbl['SII6716_FLUX_CORR']/tbl['SII6730_FLUX_CORR'])    \n",
    "        tbl['OII3727/HB'] = np.log10(tbl['OII3726_FLUX_CORR']/tbl['HB4861_FLUX_CORR'])    \n",
    "    return tbl\n",
    "\n",
    "HII_regions = calculate_ratios(nebulae_catalogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import match_coordinates_sky, Angle\n",
    "\n",
    "matchcoord   = HII_regions[HII_regions['region_area']<100]\n",
    "catalogcoord = signals[signals['in_frame']]\n",
    "\n",
    "idx,sep,_=match_coordinates_sky(matchcoord['SkyCoord'],catalogcoord['SkyCoord'])\n",
    "crit = sep.__lt__(Angle('.5\"'))\n",
    "\n",
    "lines = ['log(NII6583/HA)','log(SII6716+6731/HA)',\n",
    "         'log(OIII5007/HB)','log(OIII5007/NII6583)','log(SII6717/SII6731)',\n",
    "         'log(OII3727/HB)']\n",
    "\n",
    "for line in lines:\n",
    "    matchcoord[line] = catalogcoord[idx][line]\n",
    "matchcoord['HA_signals'] = 1e20*(catalogcoord[idx]['HA_FLUX']*u.cm**2).value\n",
    "matchcoord = matchcoord[crit]\n",
    "\n",
    "#print(f'SIGNALS in MUSE frame: {np.sum(catalogcoord[\"in_frame\"])}')\n",
    "print(f'{np.sum(crit)} matches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = 1e3,7e6\n",
    "fig,ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(matchcoord['HA6562_FLUX_CORR'],matchcoord['HA_signals'])\n",
    "ax.plot(lim,lim,color='black')\n",
    "ax.set(xlim=lim,ylim=lim,xlabel=r'H$\\alpha$ PHANGS MUSE',ylabel=r'H$\\alpha$ SIGNALS SITELLE',xscale='log',yscale='log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(4,4))\n",
    "ax=fig.add_subplot(projection=Halpha.wcs)\n",
    "\n",
    "norm = simple_norm(Halpha.data,clip=False,stretch='asinh',percent=80)\n",
    "ax.imshow(Halpha.data,norm=norm,cmap=plt.cm.Greys)\n",
    "\n",
    "x,y = catalogcoord[idx]['SkyCoord'].to_pixel(Halpha.wcs)\n",
    "plt.scatter(x,y,marker='o',fc='none',ec='tab:red',s=2,lw=0.1,label='SIGNALS')\n",
    "\n",
    "for coords in muse_regions.contours[:-1]: \n",
    "    ax.plot(coords[:,1],coords[:,0],color='tab:blue',lw=0.2)\n",
    "\n",
    "ax.plot(muse_regions.contours[-1][:,1],muse_regions.contours[-1][:,0],color='tab:blue',lw=0.2,label='PHANGS')\n",
    "\n",
    "lon = ax.coords[0]\n",
    "lat = ax.coords[1]\n",
    "lon.set_ticks_visible(False)\n",
    "lon.set_ticklabel_visible(False)\n",
    "lat.set_ticks_visible(False)\n",
    "lat.set_ticklabel_visible(False)\n",
    "lon.set_axislabel('')\n",
    "lat.set_axislabel('')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(basedir/'reports'/name/f'{name}_signals_regions.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(nrows=2,ncols=3,figsize=(10,6))\n",
    "\n",
    "axes_iter=iter(axes.flatten())\n",
    "\n",
    "for line in lines:\n",
    "    ax = next(axes_iter)\n",
    "    \n",
    "    ax.scatter(matchcoord[line],matchcoord[line[4:-1]])\n",
    "    #ax.plot([-3,3],[-3,3])\n",
    "    ax.set(xlabel=f'{line} SIGNALS',ylabel=f'{line} PHANGS')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(basedir/'reports'/name/f'{name}_muse_regions_line_ratios_vs_signal.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remeasure fluxes \n",
    "\n",
    "we use the positions from Rousseau-Nepton+2018 to measure the line fluxes in the MUSEDAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ID','SkyCoord','log(NII6583/HA)','log(SII6716+6731/HA)',\n",
    "         'log(OIII5007/HB)','log(OIII5007/NII6583)','log(SII6717/SII6731)']\n",
    "\n",
    "sample = signals[columns][signals['in_frame']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils import SkyCircularAperture, SkyCircularAnnulus, aperture_photometry\n",
    "\n",
    "apertures = SkyCircularAperture(sample['SkyCoord'],1*u.arcsec)\n",
    "annuli    = SkyCircularAnnulus(sample['SkyCoord'],3*u.arcsec,4*u.arcsec)\n",
    "\n",
    "with fits.open(data_raw/'MUSE_DR2.1'/'MUSEDAP'/'NGC0628_MAPS.fits') as hdul:\n",
    "    for line in ['HB4861','OIII5006','HA6562','NII6583','SII6716','SII6730']:\n",
    "        data = hdul[f'{line}_FLUX'].data\n",
    "        wcs  = WCS(hdul[f'{line}_FLUX'].header)\n",
    "        sample[line] = aperture_photometry(data,apertures,wcs=wcs)['aperture_sum']\n",
    "        sample[f'{line}_bkg'] = aperture_photometry(data,annuli,wcs=wcs)['aperture_sum'] / 4\n",
    "\n",
    "sample['HB4861']   = sample['HB4861'] - sample['HB4861_bkg']\n",
    "sample['OIII5006'] = sample['OIII5006'] - sample['OIII5006_bkg']\n",
    "sample['HA6562']   = sample['HA6562'] - sample['HA6562_bkg']\n",
    "sample['NII6583']  = sample['NII6583'] - sample['NII6583_bkg']\n",
    "sample['SII6716']  = sample['SII6716'] - sample['SII6716_bkg']\n",
    "sample['SII6730']  = sample['SII6730'] - sample['SII6730_bkg']\n",
    "\n",
    "sample['NII6583/HA']       = sample['NII6583']/sample['HA6562']\n",
    "sample['SII6716+6731/HA']  = (sample['SII6716']+sample['SII6730'])/sample['HA6562']\n",
    "sample['OIII5007/HB']      = sample['OIII5006']/sample['HB4861']\n",
    "sample['OIII5007/NII6583'] = sample['OIII5006']/sample['NII6583']\n",
    "sample['SII6717/SII6731']  = sample['SII6716']/sample['SII6730']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(nrows=2,ncols=3,figsize=(9,6))\n",
    "\n",
    "axes_iter=iter(axes.flatten())\n",
    "\n",
    "for line in columns[2:]:\n",
    "    ax = next(axes_iter)\n",
    "    \n",
    "    ax.scatter(sample[line],sample[line[4:-1]])\n",
    "    #ax.plot([-3,3],[-3,3])\n",
    "    ax.set(xlabel=f'{line} SIGNALS',ylabel=f'{line} PHANGS')\n",
    "    ax.set(xlim=[0,2],ylim=[0,2])\n",
    "    \n",
    "ax = next(axes_iter)\n",
    "ax.remove()\n",
    "plt.tight_layout()\n",
    "plt.savefig(basedir/'reports'/name/f'{name}_signal_regions_line_ratios.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Astrometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'NGC0628'\n",
    "data_ext = Path('a:')\n",
    "\n",
    "with fits.open(data_ext / 'WFI' / f'{name}_Rc_flux_nosky.fits') as hdul:\n",
    "    WFI = NDData(data=hdul[0].data,\n",
    "                 meta=hdul[0].header,\n",
    "                 wcs=WCS(hdul[0].header))\n",
    "    \n",
    "with fits.open(data_ext/'MUSE_DR2'/'MUSEDAP'/f'{name}_MAPS.fits') as hdul:    \n",
    "    Halpha = NDData(data=hdul['HA6562_FLUX'].data,\n",
    "                    mask=np.isnan(hdul['HA6562_FLUX'].data),\n",
    "                    meta=hdul['HA6562_FLUX'].header,\n",
    "                    wcs=WCS(hdul['HA6562_FLUX'].header))    \n",
    "    \n",
    "with fits.open(data_ext/'SITELLE'/f'{name}_cube.fits') as hdul:\n",
    "    wcs = WCS(hdul[0].header,naxis=2)\n",
    "\n",
    "with fits.open(data_ext/'SITELLE'/f'{name}_deepframe.fits') as hdul:\n",
    "    deepframe = NDData(data=hdul[0].data,\n",
    "                    meta=hdul[0].header,\n",
    "                    wcs=WCS(hdul[0].header))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reproject import reproject_interp\n",
    "\n",
    "deepframe_wfi = reproject_interp((deepframe.data,wcs),Halpha.meta,return_footprint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax  = fig.add_subplot(projection=Halpha.wcs)\n",
    "\n",
    "norm = simple_norm(Halpha.data,clip=False,percent=99)\n",
    "ax.imshow(Halpha.data,norm=norm,cmap=plt.cm.Greys)\n",
    "\n",
    "#norm = simple_norm(deepframe_wfi,clip=False,percent=99)\n",
    "#ax.imshow(deepframe_wfi,norm=norm,cmap=plt.cm.Greys)\n",
    "plt.savefig('wfi.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract TYPHOON regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'NGC2835'\n",
    "\n",
    "with fits.open(basedir/'data'/'typhoon'/'NGC2835_Halpha_WCS.fits') as hdul:\n",
    "    typhoon_halpha = NDData(data=hdul[0].data,\n",
    "                 meta=hdul[0].header,\n",
    "                 wcs=WCS(hdul[0].header))\n",
    "with fits.open(basedir/'..'/'sitelle'/'data'/'typhoon'/'N2835_TG10_sig3.50000_hiiphot_WCS.fits') as hdul:\n",
    "    typhoon_mask = NDData(data=hdul[0].data,\n",
    "                     meta=hdul[0].header,\n",
    "                     wcs=typhoon_halpha.wcs)\n",
    "\n",
    "names = ['HIIregion','Rgal(kpc)','Halpha','Halpha_e','Hbeta','Hbeta_e',\n",
    "         'OIII5007','OIII5007_e','OIII4636','OIII4636_e',\n",
    "         'NII6583','NII6583_e','SII6716,31','SII6716,31_e',\n",
    "         'OII3726,29','OII3726,29_e','SII6716','SII6716_e',\n",
    "         'SII6731','SII6731_e']\n",
    "\n",
    "typhoon_catalogue = ascii.read(basedir/'data'/'typhoon'/'NGC2835_HIIdata_notdereddened_WCS.dat',names=names)\n",
    "typhoon_regions = Regions(typhoon_mask.data,projection=typhoon_halpha.wcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typhoon_sitelle = reproject_interp(typhoon_mask,\n",
    "                                 output_projection=wcs,\n",
    "                                 shape_out=deepframe.data.shape,\n",
    "                                 order='nearest-neighbor',return_footprint=False)    \n",
    "typhoon_regions_sitelle = Regions(typhoon_sitelle,projection=wcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typhoon_regions_sitelle.plot(image=deepframe.data,regions=False,\n",
    "                     filename=None,\n",
    "                     xlim=[0.95*xmin,1.05*xmax],ylim=[0.95*ymin,1.05*ymax],xlabel='R.A.',ylabel='Dec.', \n",
    "                     percent=99.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only need to extract this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_id = []\n",
    "axis      = []\n",
    "spectrum  = []\n",
    "\n",
    "print(f'extracting {len(typhoon_regions_sitelle.labels)} HII region spectra')\n",
    "for reg,label in zip(typhoon_regions_sitelle.coords,typhoon_regions_sitelle.labels):\n",
    "\n",
    "    # ORCS expects y,x coordinates\n",
    "    a,s = cube.extract_integrated_spectrum(reg[::-1])\n",
    "\n",
    "    region_id.append(label)\n",
    "    axis.append(np.float64(a))\n",
    "    spectrum.append(np.real(s))\n",
    "        \n",
    "\n",
    "spectra = Table(data=[region_id,axis,spectrum],\n",
    "                names=['region_ID','axis','spectrum'])\n",
    "\n",
    "spectra['axis'] /= u.cm\n",
    "spectra['spectrum'] *= u.erg/u.cm**2/u.s/u.AA\n",
    "\n",
    "hdu = fits.BinTableHDU(spectra,name='spectra')\n",
    "hdu.writeto(basedir/'data'/'typhoon'/f'{name}_typhoon_spectra_SN1.fits',overwrite=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orb.fit import fit_lines_in_spectrum\n",
    "from orb.core import Lines\n",
    "from orb.utils.spectrum import corr2theta, amp_ratio_from_flux_ratio\n",
    "import gvar\n",
    "\n",
    "\n",
    "with fits.open(basedir/'data'/'typhoon'/f'{name}_typhoon_spectra_SN1.fits') as hdul:\n",
    "    spectra = Table(hdul[1].data)\n",
    "spectra.add_index('region_ID')\n",
    "\n",
    "# parameters from the cube, needed for the fit\n",
    "parameter_file = basedir/'data'/output_folder/'params'/f'{name}_params.yaml'\n",
    "with open(parameter_file) as f:\n",
    "    params = yaml.load(f,Loader=yaml.SafeLoader)\n",
    "    \n",
    "distances = {\n",
    "             'IC5332':29.736,'NGC0628':29.9,'NGC1087':30.352,'NGC1300':32.065,'NGC1365':31.242,\n",
    "             'NGC1385':29.659,'NGC1433':31.369,'NGC1512':31.506,'NGC1566':30.884,'NGC1672':30.788,\n",
    "             'NGC2835':30.563,'NGC3351':30.338,'NGC3627':30.133,'NGC4254':30.102,'NGC4303':30.688,\n",
    "             'NGC4321':31.121,'NGC4535':30.99,'NGC5068':28.475,'NGC7496':31.347,\n",
    "            }\n",
    "\n",
    "# EBV of the galaxies\n",
    "EBV = {'IC5332': 0.015,'NGC0628': 0.062,'NGC1087': 0.03,'NGC1300': 0.026,'NGC1365': 0.018,\n",
    "       'NGC1385': 0.018,'NGC1433': 0.008,'NGC1512': 0.009,'NGC1566': 0.008,'NGC1672': 0.021,\n",
    "       'NGC2835': 0.089,'NGC3351': 0.024,'NGC3627': 0.037,'NGC4254': 0.035,'NGC4303': 0.02,\n",
    "       'NGC4321': 0.023,'NGC4535': 0.017,'NGC5068': 0.091,'NGC7496': 0.008}\n",
    "\n",
    "H0 = 70 * u.km / u.s / u.Mpc\n",
    "velocity = H0*Distance(distmod=distances[name])\n",
    "z = (velocity / c.c).decompose().value\n",
    "\n",
    "print(f'velocity={velocity:.1f},z={z:.3f}')\n",
    "\n",
    "OII3726 = Lines().get_line_cm1('[OII]3726')\n",
    "OII3729 = Lines().get_line_cm1('[OII]3729')\n",
    "\n",
    "# channel_width in km/s (velocity must be more precise than this)\n",
    "#channel_width = cube.params.base_axis[1] - cube.params.base_axis[0]\n",
    "#print(f'channel width: {(c.c * channel_width / OII3726).to(u.km/u.s):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "extinction_model = CCM89(Rv=3.1)\n",
    "extinction_mw26  = extinction_model.extinguish(3626*u.angstrom,Ebv=0.5*EBV[name])\n",
    "extinction_mw29  = extinction_model.extinguish(3629*u.angstrom,Ebv=0.5*EBV[name])\n",
    "\n",
    "# table to save the fluxes\n",
    "fluxes = Table(data=np.full((len(spectra),9),fill_value=np.nan),\n",
    "               names=['region_ID','OII3726_FLUX','OII3729_FLUX','OII3726_FLUX_ERR','OII3729_FLUX_ERR',\n",
    "                      'OII3726_velocity','OII3729_velocity','OII3726_broadening','OII3729_broadening'])\n",
    "fluxes.add_column(name,index=0,name='gal_name')\n",
    "fluxes['region_ID'] = list(spectra['region_ID'])\n",
    "fluxes.add_index('region_ID')\n",
    "\n",
    "# table to save the line parameters\n",
    "lines_params = Table(data=np.full((len(spectra),11),fill_value=np.nan),\n",
    "               names=['region_ID','height_OII3726','amp_OII3726','pos_OII3726','fwhm_OII3726','sigma_OII3726',\n",
    "                      'height_OII3729','amp_OII3729','pos_OII3729','fwhm_OII3729','sigma_OII3729'])\n",
    "lines_params['region_ID'] = list(spectra['region_ID'])\n",
    "lines_params.add_index('region_ID')\n",
    "\n",
    "# table to save the fitted vector\n",
    "fit_table = spectra.copy()\n",
    "fit_table['OII3726'] = 0*spectra['spectrum']\n",
    "fit_table['OII3729'] = 0*spectra['spectrum']\n",
    "fit_table['fit'] = 0*spectra['spectrum']\n",
    "\n",
    "\n",
    "for region_ID in tqdm(fluxes['region_ID']):\n",
    "    \n",
    "    axis,spectrum = spectra.loc[region_ID][['axis','spectrum']]\n",
    "\n",
    "    # we run each fit twice. First with the SNR guess from the classic fit\n",
    "    try:\n",
    "        SNR = 3 #result.loc[region_ID]['OII3727_FLUX'] / result.loc[region_ID]['OII3727_FLUX_ERR']    \n",
    "        fit = fit_spectrum(spectrum,params,velocity,SNR)\n",
    "        #SNR = fit['snr'][0] #fit['flux'][0]/fit['flux_err'][0]\n",
    "        position = fit['lines_params'][1][2]\n",
    "        residual = fit.get_residual().data\n",
    "        amp = fit['lines_params'][1][1]\n",
    "        std = np.std(residual[(axis>position-100)&(axis<position+100)])\n",
    "        SNR = amp/std\n",
    "        fit = fit_spectrum(spectrum,params,velocity,SNR)\n",
    "        \n",
    "        # save the line parameters\n",
    "        lines_params.loc[region_ID][list(lines_params.columns[1:])] = fit['lines_params'].flatten()\n",
    "        \n",
    "        # save the fit result\n",
    "        OII3726_fit, OII3729_fit = fit['fitted_models']['Cm1LinesModel']        \n",
    "        fit_table.loc[region_ID]['OII3726'] = OII3726_fit\n",
    "        fit_table.loc[region_ID]['OII3729'] = OII3729_fit\n",
    "        fit_table.loc[region_ID]['fit']     = fit['fitted_vector']\n",
    "\n",
    "        # the main table\n",
    "        fluxes.loc[region_ID]['OII3726_FLUX','OII3729_FLUX']             = 1e20*fit['flux']\n",
    "        fluxes.loc[region_ID]['OII3726_FLUX_ERR','OII3729_FLUX_ERR']     = 1e20*fit['flux_err']\n",
    "        fluxes.loc[region_ID]['OII3726_velocity','OII3729_velocity']     = fit['velocity']\n",
    "        fluxes.loc[region_ID]['OII3726_broadening','OII3729_broadening'] = fit['broadening']\n",
    "        \n",
    "        # correct for extinction\n",
    "        fluxes.loc[region_ID]['OII3726_FLUX'] /= extinction_mw26\n",
    "        fluxes.loc[region_ID]['OII3729_FLUX'] /= extinction_mw29\n",
    "\n",
    "    except:\n",
    "        print(f'error for {region_ID}')\n",
    "\n",
    "# save the table with the fluxes\n",
    "hdu = fits.BinTableHDU(fluxes,name='fluxes')\n",
    "hdu.writeto(basedir/'data'/'typhoon'/f'{name}_typhoon_OII_fluxes_fixed_sigma.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "213.5px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
